{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NTDS'19] assignment 1: network science\n",
    "[ntds'19]: https://github.com/mdeff/ntds_2019\n",
    "\n",
    "[Eda Bayram](https://lts4.epfl.ch/bayram), [EPFL LTS4](https://lts4.epfl.ch) and\n",
    "[Nikolaos Karalias](https://people.epfl.ch/nikolaos.karalias), [EPFL LTS2](https://lts2.epfl.ch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students\n",
    "\n",
    "* Team: 8\n",
    "* Students: Adrian Villarroel (for the indivudual submission) or Ariel Alba, Andres Montero, Elias Poroma, Adrian Villarroel (for the team submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "\n",
    "Grading:\n",
    "* The first deadline is for individual submissions. The second deadline is for the team submission.\n",
    "* All team members will receive the same grade based on the team solution submitted on the second deadline.\n",
    "* As a fallback, a team can ask for individual grading. In that case, solutions submitted on the first deadline are graded.\n",
    "* Collaboration between team members is encouraged. No collaboration between teams is allowed.\n",
    "\n",
    "Submission:\n",
    "* Textual answers shall be short. Typically one to two sentences.\n",
    "* Code has to be clean.\n",
    "* You cannot import any other library than we imported.\n",
    "  Note that Networkx is imported in the second section and cannot be used in the first.\n",
    "* When submitting, the notebook is executed and the results are stored. I.e., if you open the notebook again it should show numerical results and plots. We won't be able to execute your notebooks.\n",
    "* The notebook is re-executed from a blank state before submission. That is to be sure it is reproducible. You can click \"Kernel\" then \"Restart Kernel and Run All Cells\" in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The purpose of this milestone is to explore a given dataset, represent it by network by constructing different graphs. In the first section, you will analyze the network properties. In the second section, you will explore various network models and find out the network model fitting the ones you construct from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cora Dataset\n",
    "\n",
    "The [Cora dataset](https://linqs.soe.ucsc.edu/node/236) consists of scientific publications classified into one of seven research fields. \n",
    "\n",
    "* **Citation graph:** the citation network can be constructed from the connections given in the `cora.cites` file.\n",
    "* **Feature graph:** each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary and its research field, given in the `cora.content` file. The dictionary consists of 1433 unique words. A feature graph can be constructed using the Euclidean distance between the feature vector of the publications.\n",
    "\n",
    "The [`README`](data/cora/README) provides details about the content of [`cora.cites`](data/cora/cora.cites) and [`cora.content`](data/cora/cora.content)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Network Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Construct a Citation Graph and a Feature Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the `cora.content` file into a Pandas DataFrame by setting a header for the column names. Check the `README` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "column_list = (\n",
    "    [\"paper_id\"] + [\"w\" + str(x) for x in range(1,1434)] + [\"class_label\"]\n",
    ") \n",
    "pd_content = pd.read_csv(DATA_PATH + \"/cora/cora.content\", \n",
    "                         delimiter=\"\\t\",\n",
    "                         names=column_list) \n",
    "pd_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the number of papers contained in each of the reasearch fields.\n",
    "\n",
    "**Hint:** You can use the `value_counts()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "pd.value_counts(pd_content[\"class_label\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select all papers from a field of your choice and store their feature vectors into a NumPy array.\n",
    "Check its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "my_field = \"Neural_Networks\" \n",
    "features = (\n",
    "    pd_content[pd_content[\"class_label\"] == my_field]\n",
    "    .iloc[:, 1: pd_content.shape[1] - 1]\n",
    "    .values\n",
    ")\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $D$ be the Euclidean distance matrix whose $(i,j)$ entry corresponds to the Euclidean distance between feature vectors $i$ and $j$.\n",
    "Using the feature vectors of the papers from the field which you have selected, construct $D$ as a Numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# With this test we can verify numpy broadcast for Euclidean distance\n",
    "v1 = np.asarray([2,1,3])\n",
    "v2 = np.asarray([6,5,7])\n",
    "v3 = np.asarray([2,3,4])\n",
    "mat = np.asarray([v1,v2,v3])\n",
    "print(\"Matrix\")\n",
    "print(mat)\n",
    "d_mat = np.linalg.norm(mat - mat[:, np.newaxis, :],axis=2)\n",
    "print(\"Distance matrix\")\n",
    "print(d_mat)\n",
    "print(\"Individual vector Euclidean distance\")\n",
    "print(np.linalg.norm(v1 - v2))\n",
    "print(np.linalg.norm(v1 - v3))\n",
    "print(np.linalg.norm(v2 - v3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "distance_matrix = np.linalg.norm(features - features[:, np.newaxis, :], \n",
    "                                 axis=2) \n",
    "distance_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the mean pairwise distance $\\mathbb{E}[D]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "mean_distance = distance_matrix.mean()\n",
    "mean_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot an histogram of the euclidean distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(8, 4))\n",
    "plt.title(\"Histogram of Euclidean distances between papers\")\n",
    "plt.hist(distance_matrix.flatten());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create an adjacency matrix for the papers by thresholding the Euclidean distance matrix.\n",
    "The resulting (unweighted) adjacency matrix should have entries\n",
    "$$ A_{ij} = \\begin{cases} 1, \\; \\text{if} \\; d(i,j)< \\mathbb{E}[D], \\; i \\neq j, \\\\ 0, \\; \\text{otherwise.} \\end{cases} $$\n",
    "\n",
    "First, let us choose the mean distance as the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "threshold = mean_distance\n",
    "# Your code here\n",
    "A_feature = (\n",
    "    np.where(distance_matrix < threshold, 1, 0) \n",
    "    - \n",
    "    np.eye(distance_matrix.shape[0])\n",
    ")\n",
    "A_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read the `cora.cites` file and construct the citation graph by converting the given citation connections into an adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "cora_cites = np.genfromtxt(DATA_PATH + \"/cora/cora.cites\",\n",
    "                           delimiter=\"\\t\")\n",
    "\n",
    "index = np.vectorize(dict(zip(pd_content[\"paper_id\"], \n",
    "                              pd_content[\"paper_id\"].index)).get)(cora_cites) \n",
    "A_citation = np.zeros((pd_content.shape[0], pd_content.shape[0]))\n",
    "A_citation[index[:, 0],index[:, 1]] = 1\n",
    "A_citation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the adjacency matrix of the citation graph for the field that you chose.\n",
    "You have to appropriately reduce the adjacency matrix of the citation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Test np.ix_()\n",
    "a = np.asarray([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12],\n",
    "    [13, 14, 15, 16]\n",
    "])\n",
    "b = a[np.ix_(np.asarray([1, 3]),np.asarray([0, 3]))]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "my_f_index = (\n",
    "    pd_content[pd_content[\"class_label\"] == my_field]\n",
    "    .index\n",
    "    .values\n",
    "    .astype(np.intp)\n",
    ")\n",
    "A_citation = A_citation[np.ix_(my_f_index, my_f_index)]\n",
    "A_citation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if your adjacency matrix is symmetric. Symmetrize your final adjacency matrix if it's not already symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check if symmetric since it is an unweighted graph\n",
    "np.all(A_citation - A_citation.T == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Symmetrization\n",
    "A_citation = np.where((A_citation + A_citation.T) > 0, 1, 0) \n",
    "# A_citation = A_citation.T@A_citation\n",
    "np.count_nonzero(A_citation - A_citation.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Check values from citation matrix\n",
    "np.unique(A_citation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape of your adjacency matrix again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "A_citation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Degree Distribution and Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the total number of edges in each graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "num_edges_feature = np.sum(A_feature) / 2 # Undirected graph\n",
    "num_edges_citation = np.sum(A_citation) # Directed graph\n",
    "print(f\"Number of edges in the feature graph: {num_edges_feature}\")\n",
    "print(f\"Number of edges in the citation graph: {num_edges_citation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the degree distribution histogram for each of the graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# (Added by Adrian) Show degree calculation simple example\n",
    "test_a_citation = np.asarray([[0, 1, 1], [0, 0, 1], [1, 0, 0]])\n",
    "print(test_a_citation)\n",
    "print(\"K_out = \" + str(np.sum(test_a_citation, axis=1)))\n",
    "print(\"K_in = \" + str(np.sum(test_a_citation, axis=0)))\n",
    "print(\"K = \" + str(np.sum(test_a_citation, axis=0) + \n",
    "                   np.sum(test_a_citation, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "degrees_citation = ( # It is directed\n",
    "    np.sum(A_citation, axis=0) +np.sum(A_citation, axis=1)\n",
    ") \n",
    "degrees_feature = np.sum(A_feature, axis=0) # It is undirected\n",
    "\n",
    "deg_hist_normalization = (\n",
    "    np.ones(degrees_citation.shape[0]) / degrees_citation.shape[0]\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "axes[0].set_title(\"Citation graph degree distribution\")\n",
    "axes[0].hist(degrees_citation, weights=deg_hist_normalization);\n",
    "axes[1].set_title(\"Feature graph degree distribution\")\n",
    "axes[1].hist(degrees_feature, weights=deg_hist_normalization);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the first and second moments of the degree distribution of each graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "cit_moment_1 = np.mean(degrees_citation)\n",
    "cit_moment_2 = np.var(degrees_citation)\n",
    "\n",
    "feat_moment_1 = np.mean(degrees_feature)\n",
    "feat_moment_2 = np.var(degrees_feature)\n",
    "\n",
    "print(f\"1st moment of citation graph: {cit_moment_1}\") \n",
    "print(f\"2nd moment of citation graph: {cit_moment_2}\") \n",
    "print(f\"1st moment of feature graph: {feat_moment_1}\") \n",
    "print(f\"2nd moment of feature graph: {feat_moment_2}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What information do the moments provide you about the graphs?\n",
    "Explain the differences in moments between graphs by comparing their degree distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** The first moment is the average number of nodes connected to a node and the second moment is the variance. The citation degree distribution has all of its points concentrated in the range 0-6.5, that is why the average and the variance are low, whereas points of the feature distribution are distributed in the range 100-800 and highly concentrated in the range 100-300 resulting in a higher average and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the 20 largest hubs for each of the graphs and remove them. Observe the sparsity pattern of the adjacency matrices of the citation and feature graphs before and after such a reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "n = 20\n",
    "index_hubs_A_feature = (-degrees_feature).argsort()[:n]\n",
    "index_hubs_A_citation = (-degrees_citation).argsort()[:n]\n",
    "reduced_A_feature = np.delete(np.delete(A_feature, \n",
    "                                        index_hubs_A_feature, \n",
    "                                        axis=0), \n",
    "                              index_hubs_A_feature,\n",
    "                              axis=1)\n",
    "reduced_A_citation = np.delete(np.delete(A_citation,\n",
    "                                         index_hubs_A_citation,\n",
    "                                         axis = 0),\n",
    "                               index_hubs_A_citation, \n",
    "                               axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
    "axes[0, 0].set_title(\n",
    "    \"Feature graph: adjacency matrix sparsity pattern\"\n",
    ")\n",
    "axes[0, 0].spy(A_feature);\n",
    "axes[0, 1].set_title(\n",
    "    \"Feature graph without top 20 hubs: adjacency matrix sparsity pattern\"\n",
    ")\n",
    "axes[0, 1].spy(reduced_A_feature);\n",
    "axes[1, 0].set_title(\n",
    "    \"Citation graph: adjacency matrix sparsity pattern\"\n",
    ")\n",
    "axes[1, 0].spy(A_citation);\n",
    "axes[1, 1].set_title(\n",
    "    \"Citation graph without top 20 hubs: adjacency matrix sparsity pattern\"\n",
    ")\n",
    "axes[1, 1].spy(reduced_A_citation);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the new degree distribution histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "reduced_degrees_feat = np.sum(reduced_A_feature, axis=0) \n",
    "reduced_degrees_cit = (\n",
    "    np.sum(reduced_A_citation, axis=0) \n",
    "    + \n",
    "    np.sum(reduced_A_citation, axis=1)\n",
    ")\n",
    "\n",
    "deg_hist_normalization = (\n",
    "    np.ones(reduced_degrees_feat.shape[0])\n",
    "    /\n",
    "    reduced_degrees_feat.shape[0]\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "axes[0].set_title(\"Citation graph degree distribution\")\n",
    "axes[0].hist(reduced_degrees_cit, weights=deg_hist_normalization);\n",
    "axes[1].set_title(\"Feature graph degree distribution\")\n",
    "axes[1].hist(reduced_degrees_feat, weights=deg_hist_normalization);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the first and second moments for the new graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "reduced_cit_moment_1 = np.mean(reduced_degrees_cit) \n",
    "reduced_cit_moment_2 = np.var(reduced_degrees_cit)\n",
    "\n",
    "reduced_feat_moment_1 = np.mean(reduced_degrees_feat) \n",
    "reduced_feat_moment_2 = np.var(reduced_degrees_feat)\n",
    "\n",
    "print(\"Citation graph first moment:\", reduced_cit_moment_1)\n",
    "print(\"Citation graph second moment:\", reduced_cit_moment_2)\n",
    "print(\"Feature graph first moment: \", reduced_feat_moment_1)\n",
    "print(\"Feature graph second moment: \", reduced_feat_moment_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of edges in the reduced graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "reduced_num_edges_feature = np.sum(reduced_A_feature) / 2. # It is undirected\n",
    "reduced_num_edges_citation = np.sum(reduced_A_citation) # It is directed\n",
    "print(\n",
    "    f\"Number of edges in the reduced feature graph: {reduced_num_edges_feature}\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of edges in the reduced citation graph: {reduced_num_edges_citation}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the effect of removing the hubs the same for both networks? Look at the percentage changes for each moment. Which of the moments is affected the most and in which graph? Explain why.  \n",
    "\n",
    "**Hint:** Examine the degree distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** The effect is larger for the citation network because it has few nodes that have a degree significantly larger from the average (hubs). The second moment in the citation graph is affected the most because, according to the degree distribution, there was a small portion of nodes having degrees higher than 8 which accounted for most of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "delta_cit_moment_1 = (\n",
    "    (cit_moment_1 - reduced_cit_moment_1) * 100 / cit_moment_1\n",
    ")\n",
    "delta_cit_moment_2 = (\n",
    "    (cit_moment_2 - reduced_cit_moment_2) * 100 / cit_moment_2\n",
    ")\n",
    "\n",
    "delta_feat_moment_1 = (\n",
    "    (feat_moment_1 - reduced_feat_moment_1) * 100 / feat_moment_1\n",
    ")\n",
    "delta_feat_moment_2 = (\n",
    "    (feat_moment_2 - reduced_feat_moment_2) * 100 / feat_moment_2\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Citation moment 1 percentage change: {delta_cit_moment_1} %\" \n",
    ")\n",
    "print(\n",
    "    f\"Feature moment 1 percentage change: {delta_feat_moment_1} %\"\n",
    ")\n",
    "print(\n",
    "    f\"Citation moment 2 percentage change: {delta_cit_moment_2} %\"\n",
    ")\n",
    "print(\n",
    "    f\"Feature moment 2 percentage change: {delta_feat_moment_2} %\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Pruning, sparsity, paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adjusting the threshold of the euclidean distance matrix, prune the feature graph so that its number of edges is roughly close (within a hundred edges) to the number of edges in the citation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "mean_distance = distance_matrix.mean()\n",
    "\n",
    "# We take the new treshold as mean_distance*0.5\n",
    "threshold = mean_distance * 0.5\n",
    "\n",
    "# We create the A feature pruned with the new treshhold\n",
    "A_feature_pruned = (\n",
    "    np.where(distance_matrix < threshold, 1, 0)\n",
    "    -\n",
    "    np.eye(distance_matrix.shape[0])\n",
    ")\n",
    "\n",
    "# The number of edges is equal to the total values of the matrix /2 ,\n",
    "# is an undirected graph\n",
    "num_edges_feature_pruned = 0.5 * np.sum(A_feature_pruned)\n",
    "\n",
    "print(f\"Number of edges in the feature graph: {num_edges_feature}\")\n",
    "print(f\"Number of edges in the feature graph after pruning: {num_edges_feature_pruned}\")\n",
    "print(f\"Number of edges in the citation graph: {num_edges_citation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your results by comparing the sparsity patterns and total number of edges between the graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].set_title(\"Citation graph sparsity\")\n",
    "axes[0].spy(A_citation);\n",
    "axes[1].set_title(\"Feature graph sparsity\")\n",
    "axes[1].spy(A_feature_pruned);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $C_{k}(i,j)$ denote the number of paths of length $k$ from node $i$ to node $j$. \n",
    "\n",
    "We define the path matrix $P$, with entries\n",
    "$ P_{ij} = \\displaystyle\\sum_{k=0}^{N}C_{k}(i,j). $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the path matrices for both the citation and the unpruned feature graphs for $N =10$.  \n",
    "\n",
    "**Hint:** Use [powers of the adjacency matrix](https://en.wikipedia.org/wiki/Adjacency_matrix#Matrix_powers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "A_citation.shape\n",
    "path_matrix_citation = np.zeros((818, 818))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "path_matrix_citation = np.zeros((818, 818))\n",
    "path_matrix_feature = np.zeros((818, 818))\n",
    "\n",
    "for i in range(10 + 1):\n",
    "    path_matrix_citation += np.linalg.matrix_power(A_citation, i)\n",
    "    path_matrix_feature += np.linalg.matrix_power(A_feature, i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the sparsity pattern for both of path matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 9))\n",
    "axes[0].set_title(\"Citation Path matrix sparsity\")\n",
    "axes[0].spy(path_matrix_citation);\n",
    "axes[1].set_title(\"Feature Path matrix sparsity\")\n",
    "axes[1].spy(path_matrix_feature);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "test_0 = [[0, 0], [0, 0]]\n",
    "test_1 = [[1, 0], [0, 0]]\n",
    "test_2 = [[1, 1], [1, 1]]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 9))\n",
    "axes[0].set_title(\"Test all 0\")\n",
    "axes[0].spy(test_0);\n",
    "axes[1].set_title(\"Test some 1\")\n",
    "axes[1].spy(test_1);\n",
    "axes[2].set_title(\"Test all 1\")\n",
    "axes[2].spy(test_2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe, .spy() plot blank for all zeros or all 1 matrix, so to verify we check the min value of the path_matrix_feature and if the value is greater than 0 we conclude that the graph is fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "path_matrix_feature.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the path matrix of the pruned feature graph for $N=10$. Plot the corresponding sparsity pattern. Is there any difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "path_matrix_pruned = np.linalg.matrix_power(A_feature_pruned, 10)\n",
    "for i in range(10 + 1):\n",
    "    path_matrix_pruned += np.linalg.matrix_power(A_feature_pruned, i)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Feature Path matrix sparsity\")\n",
    "plt.spy(path_matrix_pruned);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe how you can use the above process of counting paths to determine whether a graph is connected or not. Is the original (unpruned) feature graph connected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a graph to be connected, all the pairs of vertices need to be connected, by taking the Adjancecy matrix to the power, we will get a non-zero value only if both entries are non_zero, meaning the i,j value of the matrix are connected. \n",
    "With this explanation we can conclude that feature graph unpruned is connected becausee all the i,j are connected "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the graph is connected, how can you guess its diameter using the path matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the diameter of the graph when A^k has non-zero values, meaning that all the paths are connected up until k (I+ A^1,....+ A^k), therefore the diameter is k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any of your graphs is connected, calculate the diameter using that process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def find_diameter(matrix):\n",
    "    \"\"\"Function to calculate the diameter of a graph,\n",
    "    Diameter = I + A^1 + .... + A^k up until there are no 0, \n",
    "    meaning every vertex connects with every vertex for distance K\n",
    "    \n",
    "    Args:\n",
    "        matrix: Path matrix to find the diameter of the network\n",
    "    \n",
    "    Returns:\n",
    "        i (int): Diameter of the matrix\n",
    "    \"\"\"\n",
    "    degree = 0\n",
    "    path_matrix = np.zeros(matrix.shape)\n",
    "    i=0\n",
    "    path_matrix += np.linalg.matrix_power(matrix,i)\n",
    "    while 0 in path_matrix:\n",
    "        i += 1\n",
    "        path_matrix += np.linalg.matrix_power(matrix,i)\n",
    "        \n",
    "        if i > 20:\n",
    "            print(\"infinite graph!\")\n",
    "            return \"infinite\"\n",
    "    return i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "diameter = find_diameter(A_feature)\n",
    "print(f\"The diameter is: {diameter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if your guess was correct using [NetworkX](https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.distance_measures.diameter.html).\n",
    "Note: usage of NetworkX is only allowed in this part of Section 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "feature_graph = nx.from_numpy_matrix(A_feature)\n",
    "print(f\"Diameter according to networkx: {nx.diameter(feature_graph)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Network Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will analyze the feature and citation graphs you constructed in the previous section in terms of the network model types.\n",
    "For this purpose, you can use the NetworkX libary imported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create NetworkX graph objects from the adjacency matrices computed in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "G_citation = nx.from_numpy_matrix(A_citation)\n",
    "print(\n",
    "    \"Number of nodes: {}, Number of edges: {}\"\n",
    "    .format(G_citation.number_of_nodes(),\n",
    "            G_citation.number_of_edges())\n",
    ")\n",
    "print(\n",
    "    \"Number of self-loops: {}, Number of connected components: {}\".\n",
    "    format(G_citation.number_of_selfloops(),\n",
    "           nx.number_connected_components(G_citation))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the rest of this assignment, we will consider the pruned feature graph as the feature network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "G_feature = nx.from_numpy_matrix(A_feature_pruned)\n",
    "print(\n",
    "    \"Number of nodes: {}, Number of edges: {}\".\n",
    "    format(G_feature.number_of_nodes(),\n",
    "           G_feature.number_of_edges())\n",
    ")\n",
    "print(\n",
    "    \"Number of self-loops: {}, Number of connected components: {}\"\n",
    "    .format(G_feature.number_of_selfloops(),\n",
    "            nx.number_connected_components(G_feature))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Simulation with Erdős–Rényi and Barabási–Albert models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an Erdős–Rényi and a Barabási–Albert graph using NetworkX to simulate the citation graph and the feature graph you have. When choosing parameters for the networks, take into account the number of vertices and edges of the original networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of nodes should exactly match the number of nodes in the original citation and feature graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(G_citation.nodes()) == len(G_feature.nodes())\n",
    "n = len(G_citation.nodes())\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of match shall fit the average of the number of edges in the citation and the feature graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "m = np.round((G_citation.size() + G_feature.size()) / 2)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you determine the probability parameter for the Erdős–Rényi graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "l_max = n * (n - 1) / 2\n",
    "p = m / l_max\n",
    "G_er = nx.erdos_renyi_graph(n, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of edges in the Erdős–Rényi graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"My Erdos-Rényi network has {} edges.\"\n",
    "    .format(G_er.size())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The expected number of edges is $$E[m]=pn(n-1)/2$$ thus, to calculate the probability parameter $$p$$ \n",
    "first the maximum number of edges must be calculated $$n(n-1)/2$$ and since $$E[m]$$ is the average number \n",
    "of edges, the average number of edges must be divided by the theoretical maximum number of edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you determine the preferential attachment parameter for Barabási–Albert graphs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "res1 = int((n + np.sqrt(n ** 2 - 4 * m)) / 2)\n",
    "res2 = int((n - np.sqrt(n ** 2 - 4 * m)) / 2)\n",
    "# Taking the max because q must be greater than 1 and \n",
    "# int() becuase it has to be a natural number\n",
    "q = max(res1, res2)\n",
    "G_ba = nx.barabasi_albert_graph(n, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of edges in the Barabási–Albert graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"My Barabási-Albert network has {} edges.\"\n",
    "    .format(G_ba.size())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected number of edges is $$m=q(n-q)$$, thus, to calculate the preferential attachment parameter $$q$$, \n",
    "the previous equation must be solved and like $$q > 1 \\land q \\in \\mathbb{N}$$, the maximum value of the result of \n",
    "the equation is taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Giant Component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of the largest connected component in the citation and feature graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "giant_citation = max(nx.connected_component_subgraphs(G_citation),\n",
    "                     key=len)\n",
    "print(\n",
    "    \"The giant component of the citation graph has {} nodes and {} edges.\"\n",
    "    .format(giant_citation.number_of_nodes(), giant_citation.size())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "giant_feature = max(nx.connected_component_subgraphs(G_feature),\n",
    "                    key=len)\n",
    "print(\n",
    "    \"The giant component of the feature graph has {} nodes and {} edges.\"\n",
    "    .format(giant_feature.number_of_nodes(), giant_feature.size())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of the giant components in the generated Erdős–Rényi graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "giant_er = max(nx.connected_component_subgraphs(G_er), key=len)\n",
    "print(\"The giant component of the Erdos-Rényi network has {} nodes and {} edges.\".format(giant_er.number_of_nodes(), giant_er.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us match the number of nodes in the giant component of the feature graph by simulating a new Erdős–Rényi network.\n",
    "How do you choose the probability parameter this time? \n",
    "\n",
    "**Hint:** Recall the expected giant component size from the lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "n_new = len(G_feature.nodes())\n",
    "n_g = len(giant_feature.nodes())\n",
    "p_new = -np.log(1 - n_g / n_new) * n_new / (n_g * (n_new - 1))\n",
    "G_er_new = nx.erdos_renyi_graph(n_new, p_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of the new Erdős–Rényi network and its giant component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"My new Erdos Renyi network has {} edges.\".format(G_er_new.size()))\n",
    "giant_er_new = max(nx.connected_component_subgraphs(G_er_new), key=len)\n",
    "print(\"The giant component of the new Erdos-Rényi network has {} nodes and {} edges.\".format(giant_er_new.number_of_nodes(), giant_er_new.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Degree Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the degree distribution of the citation and the feature graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "axes[0].set_title(\"Citation graph\")\n",
    "citation_degrees = (\n",
    "    (np.sum(A_citation, axis=0) \n",
    "     + \n",
    "     np.sum(A_citation,axis = 1)).astype(int)\n",
    ")\n",
    "axes[0].hist(citation_degrees);\n",
    "axes[1].set_title(\"Feature graph\")\n",
    "feature_degrees = np.sum(A_feature, axis=0).astype(int)\n",
    "axes[1].hist(feature_degrees);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the degree distribution tell us about a network? Can you make a prediction on the network model type of the citation and the feature graph by looking at their degree distributions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** The degree distribution helps us get an idea of the degrees in the network and allows us to guess the network model type. In this example, the citation has a scale free network type of distribution, and the feature graph looks like an exponentially bounded network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, plot the degree distribution historgrams for the simulated networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "axes[0].set_title(\"Erdos-Rényi network\")\n",
    "er_degrees = np.sum(G_er, axis=0) + np.sum(A_citation, axis=1)\n",
    "axes[0].hist(er_degrees);\n",
    "axes[1].set_title(\"Barabási-Albert network\")\n",
    "ba_degrees = np.sum(G_ba, axis=0) + np.sum(A_citation, axis=1)\n",
    "axes[1].hist(ba_degrees);\n",
    "axes[2].set_title(\"New Erdos-Rényi network\")\n",
    "er_new_degrees = np.sum(G_er_new, axis=0)\n",
    "axes[2].hist(er_new_degrees);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of the degree distribution, is there a good match between the citation and feature graphs and the simulated networks?\n",
    "For the citation graph, choose one of the simulated networks above that match its degree distribution best. Indicate your preference below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** There is a good match between the shape of the distribution histogram of the citation graph and the two simulations of it. I would choose the first one, the only downside is that this simulation has a really high number of edges unlike the original graph.\n",
    "The simulated feature graph does not have a good distribution match with the original one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also simulate a network using the configuration model to match its degree disctribution exactly. Refer to [Configuration model](https://networkx.github.io/documentation/stable/reference/generated/networkx.generators.degree_seq.configuration_model.html#networkx.generators.degree_seq.configuration_model).\n",
    "\n",
    "Let us create another network to match the degree distribution of the feature graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "G_config = nx.configuration_model(feature_degrees) \n",
    "print(\"Configuration model has {} nodes and {} edges.\".format(G_config.number_of_nodes(), G_config.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it mean that we create the same graph with the feature graph by the configuration model? If not, how do you understand that they are not the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** No, because even if the degree distribution is the same, the number of edges per vertex may be very different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Clustering Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the average clustering coefficient of the original citation and feature graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "nx.average_clustering(G_citation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "nx.average_clustering(G_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the clustering coefficient tell us about a network? Comment on the values you obtain for the citation and feature graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** The clustering coefficient is an indication about the fraction of the node's neighbors that are connected. \n",
    "The average clustering coefficient will tell us the average probability that two neighbors are connecded to each other in the entire graph, not only in different clusters\n",
    "\n",
    "With that we conclude that the G_citation graph has a higher probability that two neighbors of a node link to each other in the entire graph, meaning is \"more connected\" than the G_feature graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us check the average clustering coefficient for the simulated networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "nx.average_clustering(G_er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "nx.average_clustering(G_ba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "nx.average_clustering(nx.Graph(G_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the values you obtain for the simulated networks. Is there any good match to the citation or feature graph in terms of clustering coefficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**  No there is not a good match, the G_feature and G_citation are 0.122  and 0.216 respectively, however the G_er is 0.004 (much less than G_feature and G_citation), the G_ba is 0.996 (much more than G_feature and G_citation) and G_config is 0.45 more than twice G_citation and more than 4 times G_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the other [network model generators](https://networkx.github.io/documentation/networkx-1.10/reference/generators.html) provided by NetworkX. Which one do you predict to have a better match to the citation graph or the feature graph in terms of degree distribution and clustering coefficient at the same time? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you find a better fit, create a graph object below for that network model. Print the number of edges and the average clustering coefficient. Plot the histogram of the degree distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify if there exists a better fit we will try all the different models that need the same parameters as the ones previously used:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "possibilities = [\"fast_gnp_random_graph\", \n",
    "                 \"gnp_random_graph\",\n",
    "                 \"erdos_renyi_graph\", \n",
    "                 \"binomial_graph\",\n",
    "                 \"duplication_divergence_graph\"]\n",
    "test_possibilities_avgclus = []\n",
    "test_possibilities_avgclus.append(\n",
    "    nx.average_clustering(nx.fast_gnp_random_graph(n, p, seed = 25))\n",
    ")\n",
    "test_possibilities_avgclus.append(\n",
    "    nx.average_clustering(nx.gnp_random_graph(n, p, seed = 25))\n",
    ")\n",
    "test_possibilities_avgclus.append(\n",
    "    nx.average_clustering(nx.erdos_renyi_graph(n, p, seed = 25))\n",
    ")\n",
    "test_possibilities_avgclus.append(\n",
    "    nx.average_clustering(nx.binomial_graph(n, p, seed = 25))\n",
    ")\n",
    "test_possibilities_avgclus.append(\n",
    "    nx.average_clustering(nx.duplication_divergence_graph(n, p, seed = 25))\n",
    ")\n",
    "test_possibilities_avgclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Now we will find the one with the smalles difference in \n",
    "# the clustering coef for each graph and then plot the histogram \n",
    "G_citation_fit =  []\n",
    "for i in range(len(test_possibilities_avgclus)):\n",
    "    G_citation_fit.append(nx.average_clustering(G_citation) - test_possibilities_avgclus[i])\n",
    "G_citation_fit        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n",
    "We can observe that the best fit for the clustering coef is the third option which is erdos_renyi_graph, therefore there is no better fit than the one previously used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(er_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "G_feature_fit =  []\n",
    "for i in range(len(test_possibilities_avgclus)):\n",
    "    G_feature_fit.append(nx.average_clustering(G_feature) - test_possibilities_avgclus[i])\n",
    "G_feature_fit    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n",
    "We can observe that the best fit in the clustering coef is the third option which is erdos_renyi_graph, therefore there is no better fit than the one previously used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(er_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "nx.number_of_edges(nx.fast_gnp_random_graph(n, p, seed = 25))\n",
    "test_possibilities_nbedges = []\n",
    "test_possibilities_nbedges.append(\n",
    "    nx.number_of_edges(nx.fast_gnp_random_graph(n, p, seed = 25))\n",
    ")\n",
    "test_possibilities_nbedges.append(\n",
    "    nx.number_of_edges(nx.gnp_random_graph(n, p, seed = 25))\n",
    ")\n",
    "test_possibilities_nbedges.append\n",
    "(nx.number_of_edges(nx.erdos_renyi_graph(n, p, seed = 25))\n",
    ")\n",
    "test_possibilities_nbedges.append(\n",
    "    nx.number_of_edges(nx.binomial_graph(n, p, seed = 25))\n",
    ")\n",
    "test_possibilities_nbedges.append(\n",
    "    nx.number_of_edges(nx.duplication_divergence_graph(n, p, seed = 25))\n",
    ")\n",
    "test_possibilities_nbedges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of edges in G_citation graph: \", nx.number_of_edges(G_citation))\n",
    "print(\"Number of edges in G_feature graph: \", nx.number_of_edges(G_feature))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_citation_fit_edges = []\n",
    "for i in range(len(test_possibilities_nbedges)):\n",
    "    G_citation_fit_edges.append(\n",
    "        nx.number_of_edges(G_citation) - test_possibilities_nbedges[i]\n",
    "    )\n",
    "G_citation_fit_edges "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n",
    "We can observe that the best fit for the number of edges for the Citation Graph is the first option which is fast_gnp_random_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_feature_fit_edges = []\n",
    "for i in range(len(test_possibilities_nbedges)):\n",
    "    G_feature_fit_edges.append(\n",
    "        nx.number_of_edges(G_feature) - test_possibilities_nbedges[i]\n",
    "    )\n",
    "G_feature_fit_edges "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n",
    "We can observe that the best fit for the number of edges for the G_Feature Graph is the second option which is gnp_random_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
