{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_json_to_dict(df,cols):\n",
    "    \"Transform the json values inside a column into list of dictionaries\"\n",
    "    transformed_df = df\n",
    "    for col in cols:\n",
    "        transformed_df = transformed_df.assign(**{col: df[col].apply(json.loads)})\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_dict_to_set(df,col,key):\n",
    "    \"Create a set from the values of the dictionaries give a key\"\n",
    "    get_set = lambda dict_list : set([dict_.get(key) for dict_ in dict_list])\n",
    "    return df.assign(**{col: df[col].apply(get_set)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_filter_dict_with_vals(df,col,field,values):\n",
    "    \"Filter dictionaries with specific values from a column with lists of dictionaries\"\n",
    "    filter_dicts = lambda dict_list: [dict_ for dict_ in dict_list if dict_.get(field) in values]\n",
    "    return df.assign(**{col: df[col].apply(filter_dicts)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_df = pd.read_csv(\"./data/tmdb_5000_credits.csv\",sep=',', quotechar='\"')\n",
    "credits_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"./data/tmdb_5000_movies.csv\",sep=',', quotechar='\"')\\\n",
    "                .rename({\"id\":\"movie_id\"},axis=1)\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_df_cp = credits_df.copy()\n",
    "movies_df_cp = movies_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean movies_df_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies with empty genre field\n",
    "len(movies_df_cp[movies_df_cp.astype(str)['genres'] == '[]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies with empty production_companies field\n",
    "len(movies_df_cp[movies_df_cp.astype(str)['production_companies'] == '[]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies with empty production_companies field\n",
    "len(movies_df_cp[movies_df_cp.astype(str)['production_countries'] == '[]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies with empty production_companies field\n",
    "len(movies_df_cp[movies_df_cp.astype(str)['spoken_languages'] == '[]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process movies df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_movies_df = movies_df_cp\n",
    "len(pr_movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform json to list of dictionaries within cols\n",
    "movies_df_json_cols = ['genres','production_companies','keywords','production_countries','spoken_languages']\n",
    "cols_to_drop = ['homepage','overview','tagline','original_title']\n",
    "key = 'name'\n",
    "movie_id_col = 'movie_id'\n",
    "\n",
    "pr_movies_df = col_json_to_dict(pr_movies_df,movies_df_json_cols)\n",
    "for col in movies_df_json_cols :\n",
    "    pr_movies_df = col_dict_to_set(pr_movies_df,col,key)\n",
    "pr_movies_df = pr_movies_df.drop(columns = cols_to_drop)\n",
    "pr_movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process credits df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_credits_df = credits_df_cp\n",
    "credits_df_json_cols = ['cast','crew']\n",
    "key = 'name'\n",
    "pr_credits_df = col_json_to_dict(pr_credits_df,credits_df_json_cols)\n",
    "pr_credits_df = pr_credits_df.assign(actors = pr_credits_df[credits_df_json_cols[0]] )\n",
    "for col in credits_df_json_cols:\n",
    "    if col != \"crew\":\n",
    "        pr_credits_df = col_dict_to_set(pr_credits_df,col,key)\n",
    "crew_col = 'crew'\n",
    "job_field = 'job'\n",
    "values = ['Director']\n",
    "# Filter dictionaries with Director as job\n",
    "pr_credits_df = col_filter_dict_with_vals(pr_credits_df,crew_col,job_field,values)\\\n",
    "                    .rename({crew_col:values[0]})\n",
    "pr_credits_df = col_dict_to_set(pr_credits_df,crew_col,key)\n",
    "# Get actors col\n",
    "# Only select main actors to reduce the size of the dataset\n",
    "actors_col = 'actors'\n",
    "order_field = 'order'\n",
    "# Select the number of important actors\n",
    "values = [0,1,2,3,4]\n",
    "pr_credits_df = col_filter_dict_with_vals(pr_credits_df,actors_col,order_field,values)\\\n",
    "                    .rename({crew_col:values[0]})\n",
    "\n",
    "get_value = lambda dict_: dict_.get(key)\n",
    "\n",
    "pr_credits_df = pr_credits_df.explode(actors_col)\n",
    "pr_credits_df = pr_credits_df[pr_credits_df[actors_col].notna()]\n",
    "actors_series = pr_credits_df[actors_col]\n",
    "pr_credits_df = pr_credits_df.assign(**{actors_col:pr_credits_df[actors_col].apply(get_value)})\n",
    "# Remove actor from cast\n",
    "actor_cast_col = 'actor_cast'\n",
    "pr_credits_df = pr_credits_df.reset_index(drop=True)\n",
    "remove_from_cast = lambda row: row[credits_df_json_cols[0]]-set({row[actors_col]})\n",
    "pr_credits_df = pr_credits_df.assign(\\\n",
    "                **{credits_df_json_cols[0]:pr_credits_df.apply(remove_from_cast,axis=1)})\\\n",
    "                .drop(columns='title')\n",
    "pr_credits_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_cols = ['name','gender','order']\n",
    "actors_df = json_normalize(actors_series)[actor_cols]\n",
    "actors_df = actors_df\\\n",
    "            .rename(columns ={actor_cols[0]:actors_col})\\\n",
    "            .groupby(actors_col)\\\n",
    "            .aggregate({actor_cols[1]:max,actor_cols[2]:list})\\\n",
    "            .reset_index()\\\n",
    "            .reset_index()\\\n",
    "            .rename(columns={'index':'actor_id'})\n",
    "actors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_credits_df = pr_credits_df.merge(actors_df,right_on=actors_col,left_on=actors_col,how = 'inner')\n",
    "actors_credits_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_col = 'movie_id'\n",
    "new_movie_id_col = 'new_movie_id'\n",
    "actors_movies_credits_df = actors_credits_df.merge(pr_movies_df,\\\n",
    "                                                   right_on=movie_id_col,\\\n",
    "                                                   left_on=movie_id_col,\\\n",
    "                                                   how=\"inner\")\n",
    "# Set new movie ids\n",
    "unique_movies_df = pr_movies_df[movie_id_col]\\\n",
    "                    .to_frame()\\\n",
    "                    .drop_duplicates()\\\n",
    "                    .reset_index()\\\n",
    "                    .rename(columns={\"index\":new_movie_id_col})\n",
    "actors_movies_credits_df = actors_movies_credits_df.merge(unique_movies_df,right_on=movie_id_col,left_on=movie_id_col,how='inner')\\\n",
    "                            .drop(columns=movie_id_col)\\\n",
    "                            .rename(columns={new_movie_id_col:movie_id_col})\n",
    "\n",
    "actors_movies_credits_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_movies_df = unique_movies_df.merge(pr_movies_df[['movie_id','title']].drop_duplicates(),right_on='movie_id',left_on='movie_id')\n",
    "aux_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_movies_credits_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(actors_movies_credits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_union = lambda s: reduce(set.union,s) \n",
    "actor_id_col = \"actor_id\"\n",
    "actors_agg_df = actors_movies_credits_df.groupby(actors_col).aggregate(\\\n",
    "                 {\"movie_id\":set,\"cast\":get_union,\"crew\":get_union,\"actor_id\":max,\"gender\":max,\"budget\":\"mean\",\\\n",
    "                  \"genres\":get_union,\"keywords\":get_union,\"original_language\":set,\"popularity\": \"mean\",\\\n",
    "                  \"production_companies\":get_union,\"production_countries\":get_union,\"release_date\":list,\\\n",
    "                  \"revenue\":\"mean\",\"runtime\":sum,\"spoken_languages\":get_union,\"status\":list,\"title\":set,\\\n",
    "                  \"vote_average\":\"mean\",\"vote_count\":\"mean\"})\\\n",
    "                  .set_index(actor_id_col)\n",
    "actors_agg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df = actors_agg_df[['cast','crew','production_companies','genres','movie_id']]\n",
    "nodes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_actor_id = dict(zip(actors_df[actors_col],actors_df[actor_id_col]))\n",
    "dict_id_actor = dict(zip(actors_df[actor_id_col],actors_df[actors_col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get cast intersecctions length mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "def get_intersections_length_adj_mat(col):\n",
    "    \"Get the intersecction length of the set of each entry with the set of every other entry in the column\"\n",
    "    start = timeit.default_timer()\n",
    "    adj = np.zeros((col.shape[0],col.shape[0]))\n",
    "    for (i,set_row) in enumerate (col):\n",
    "        for(j,set_col) in enumerate (col):\n",
    "            try:\n",
    "                adj[i,j] = len(set_row.intersection(set_col))\n",
    "            except AttributeError:\n",
    "                adj[i,j] = 0\n",
    "    stop = timeit.default_timer()\n",
    "    print('Time: ', stop - start)\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unions_length_adj_mat(col):\n",
    "    \"Get the unions length of the set of each entry with the set of every other entry in the column\"\n",
    "    start = timeit.default_timer()\n",
    "    adj = np.zeros((col.shape[0],col.shape[0]))\n",
    "    for (i,set_row) in enumerate(col):\n",
    "        for(j,set_col) in enumerate(col):\n",
    "            try:\n",
    "                adj[i,j] = len(set_row.union(set_col))\n",
    "            except AttributeError:\n",
    "                adj[i,j] = 0\n",
    "    stop = timeit.default_timer()\n",
    "    print('Time: ', stop - start)\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get cast intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'cast'\n",
    "cast_col = nodes_df[col]\n",
    "cast_adj_raw = get_intersections_length_adj_mat(cast_col)\n",
    "cast_adj_diag = np.diag(np.diag(cast_adj_raw))\n",
    "cast_adj = cast_adj_raw - cast_adj_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(cast_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cast_adj',cast_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cast adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_adj = np.load('cast_adj.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_degree = cast_adj.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_connected_actors_id = np.argsort(- node_degree)[:20]\n",
    "most_connected_actors = [dict_id_actor.get(id_) for id_ in most_connected_actors_id]\n",
    "actors_df[actors_df[actor_id_col].isin(most_connected_actors_id)]\n",
    "print(most_connected_actors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get cast unions length mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'cast'\n",
    "cast_col = nodes_df[col]\n",
    "cast_adj_union_raw = get_unions_length_adj_mat(cast_col)\n",
    "cast_adj_union_diag = np.diag(np.diag(cast_adj_union_raw))\n",
    "cast_adj_union = cast_adj_union_raw - cast_adj_union_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cast_adj_union, cmap='hot', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cast_adj_union',cast_adj_union)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get movies intersections length mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'movie_id'\n",
    "movie_col = nodes_df[col]\n",
    "movie_adj_raw = get_intersections_length_adj_mat(movie_col)\n",
    "movie_adj_diag = np.diag(np.diag(movie_adj_raw))\n",
    "movie_adj = movie_adj_raw - movie_adj_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(movie_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('movie_adj',movie_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get movies union length mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'movie_id'\n",
    "movie_col = nodes_df[col]\n",
    "movie_adj_union_raw = get_unions_length_adj_mat(movie_col)\n",
    "movie_adj_union_diag = np.diag(np.diag(movie_adj_union_raw))\n",
    "movie_adj_union = movie_adj_union_raw - movie_adj_union_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(movie_adj_union, cmap='hot', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('movie_adj_union',movie_adj_union)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get directors intersections lenght mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'crew'\n",
    "crew_col = nodes_df[col]\n",
    "crew_adj_raw = get_intersections_length_adj_mat(crew_col)\n",
    "crew_adj_diag = np.diag(np.diag(crew_adj_raw))\n",
    "crew_adj = crew_adj_raw - crew_adj_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(crew_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('crew_adj',crew_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get directors union length mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'crew'\n",
    "crew_col = nodes_df[col]\n",
    "crew_adj_union_raw = get_unions_length_adj_mat(crew_col)\n",
    "crew_adj_union_diag = np.diag(np.diag(crew_adj_union_raw))\n",
    "crew_adj_union = crew_adj_union_raw - crew_adj_union_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crew_adj_union, cmap='hot', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('crew_adj_union',crew_adj_union)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get production companies intersections length mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'production_companies'\n",
    "prod_comp_col = nodes_df[col]\n",
    "prod_comp_adj_raw = get_intersections_length_adj_mat(prod_comp_col)\n",
    "prod_comp_adj_diag = np.diag(np.diag(prod_comp_adj_raw))\n",
    "prod_comp_adj = prod_comp_adj_raw - prod_comp_adj_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(prod_comp_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('prod_comp_adj',prod_comp_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get production companies unions length mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'production_companies'\n",
    "prod_comp_col = nodes_df[col]\n",
    "prod_comp_adj_union_raw = get_unions_length_adj_mat(prod_comp_col)\n",
    "prod_comp_adj_union_diag = np.diag(np.diag(prod_comp_adj_union_raw))\n",
    "prod_comp_adj_union = prod_comp_adj_union_raw - prod_comp_adj_union_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(prod_comp_adj_union, cmap='hot', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('prod_comp_adj_union',prod_comp_adj_union)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get genres intersections length mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'genres'\n",
    "genres_col = nodes_df[col]\n",
    "genres_adj_raw = get_intersections_length_adj_mat(genres_col)\n",
    "genres_adj_diag = np.diag(np.diag(genres_adj_raw))\n",
    "genres_adj = genres_adj_raw - genres_adj_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(genres_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('genres_adj',genres_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get genres unions length mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'genres'\n",
    "genres_col = nodes_df[col]\n",
    "genres_adj_union_raw = get_unions_length_adj_mat(genres_col)\n",
    "genres_adj_union_diag = np.diag(np.diag(genres_adj_union_raw))\n",
    "genres_adj_union = genres_adj_union_raw - genres_adj_union_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(genres_adj_union, cmap='hot', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('genres_adj_union',genres_adj_union)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregated adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_adj = np.divide((0.3*cast_adj + 0.3 * movie_adj + 0.2*crew_adj + 0.1 * genres_adj + 0.1 * prod_comp_adj),\\\n",
    "          (0.3*cast_adj_union + 0.3 * movie_adj_union + 0.2* crew_adj_union + 0.1*genres_adj_union + 0.1 * prod_comp_adj_union))\n",
    "agg_adj = np.where(np.isnan(agg_adj),0,agg_adj)\n",
    "np.sum(agg_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.spy(agg_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(agg_adj, cmap='hot', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(agg_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(agg_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('agg_adj',agg_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test consistency of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_actor_id.get(\"Sam Worthington\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_df[actors_df[\"actors\"]==\"Adriana Barraza\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_actor_id.get(\"Andreas Berg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_df[actors_df['actor_id']==1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df.loc[0,'cast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test number of actors\n",
    "len(np.unique(actors_agg_df.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movie_id = actors_agg_df.loc[dict_actor_id.get(\"Sam Worthington\")][\"movie_id\"]\n",
    "test_movie_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movies_df = unique_movies_df[unique_movies_df[new_movie_id_col].isin(test_movie_id)]\n",
    "test_movies_df = test_movies_df.merge(pr_movies_df,right_on=movie_id_col,left_on=movie_id_col)\n",
    "test_movies_df[[movie_id_col,new_movie_id_col,'title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Sam Worthington\" in pr_credits_df.loc[0,'cast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_credits_df.loc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ntds_2019)",
   "language": "python",
   "name": "ntds_2019"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
