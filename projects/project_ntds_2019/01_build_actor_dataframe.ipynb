{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build IMDb actor dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv\n",
    "from ast import literal_eval\n",
    "from project_utils import *\n",
    "from pandas.io.json import json_normalize\n",
    "from functools import reduce\n",
    "\n",
    "%reload_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_df = pd.read_csv(\"./data/tmdb_5000_credits.csv\", sep=\",\", quotechar='\"')\n",
    "credits_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"./data/tmdb_5000_movies.csv\", sep=\",\", quotechar='\"').rename(\n",
    "    {\"id\": \"movie_id\"}, axis=1\n",
    ")\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process movies DataFrame\n",
    "Flatten and clean movies DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove movies with invalid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_movies_df = movies_df.copy()\n",
    "min_vote_count = 40\n",
    "pr_movies_df = pr_movies_df[\n",
    "    (pr_movies_df.astype(str)[\"genres\"] != \"[]\")\n",
    "    & (pr_movies_df.astype(str)[\"production_companies\"] != \"[]\")\n",
    "    & (pr_movies_df[\"budget\"] != 0)\n",
    "    & (pr_movies_df[\"revenue\"] != 0)\n",
    "    & (pr_movies_df[\"popularity\"] != 0)\n",
    "    & (pr_movies_df[\"runtime\"] != 0)\n",
    "    & (pr_movies_df[\"vote_average\"] != 0)\n",
    "    & (pr_movies_df[\"vote_count\"] >= min_vote_count)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Save a valid movies dataframe for unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_movies_df = pr_movies_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Normalize vote_average according to weighted rating formula:\n",
    "\n",
    "\\begin{equation*}\n",
    "    WR = \\frac{vr+mc}{v+m}\n",
    "\\end{equation*}\n",
    "where: <br>\n",
    "v: is the vote_count <br>\n",
    "r: is the average rating of the movie <br>\n",
    "m: is the minimum vote count <br>\n",
    "c: is the average of the average rating across all the movies <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vote_avg_col = \"norm_vote_avg\"\n",
    "norm_vote_avg = normalize_vote_rating(\n",
    "    pr_movies_df[\"vote_average\"], pr_movies_df[\"vote_count\"]\n",
    ")\n",
    "pr_movies_df = pr_movies_df.assign(**{norm_vote_avg_col: norm_vote_avg})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Check if normalization using the weighted rating formula gives reasonable values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_movies_df[[\"vote_average\", \"vote_count\", norm_vote_avg_col]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_movies_df[[\"vote_average\", \"vote_count\", norm_vote_avg_col]].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Transform json to list of dictionaries for the selected cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df_json_cols = [\n",
    "    \"genres\",\n",
    "    \"production_companies\",\n",
    "    \"keywords\",\n",
    "    \"production_countries\",\n",
    "]\n",
    "pr_movies_df = col_json_to_dict(pr_movies_df, movies_df_json_cols)\n",
    "pr_movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Transform the list of dictionaries to a set with relevant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"name\"\n",
    "for col in movies_df_json_cols:\n",
    "    pr_movies_df = col_dict_to_set(pr_movies_df, col, key)\n",
    "pr_movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Drop unuseful columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"homepage\", \"overview\", \"tagline\", \"original_title\", \"spoken_languages\"]\n",
    "pr_movies_df = pr_movies_df.drop(columns=cols_to_drop)\n",
    "pr_movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Reindex movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_movie_id_col = \"new_movie_id\"\n",
    "new_movie_id_df = (\n",
    "    pr_movies_df[\"movie_id\"].reset_index().rename({\"index\": new_movie_id_col}, axis=1)\n",
    ")\n",
    "new_movie_id_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of movies reduced to: \" + str(len(new_movie_id_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process credits DataFrame\n",
    "Flatten and clean credits DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Filter the credits only for valid movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_credits_df = credits_df.copy()\n",
    "pr_credits_df = pr_credits_df.merge(new_movie_id_df, on=\"movie_id\", how=\"inner\")\n",
    "pr_credits_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Clean the credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Raw credits dataframe length: \" + str(len(pr_credits_df)))\n",
    "pr_credits_df = pr_credits_df[\n",
    "    (pr_credits_df[\"cast\"].astype(str) != \"[]\")\n",
    "    | (pr_credits_df[\"crew\"].astype(str) != \"[]\")\n",
    "]\n",
    "print(\"Clean credits dataframe length: \" + str(len(pr_credits_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Parse json cols to list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_df_json_cols = [\"cast\", \"crew\"]\n",
    "pr_credits_df = col_json_to_dict(pr_credits_df, credits_df_json_cols)\n",
    "pr_credits_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create the actors column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_col = \"actor_name\"\n",
    "pr_credits_df = pr_credits_df.assign(\n",
    "    **{actors_col: pr_credits_df[credits_df_json_cols[0]]}\n",
    ")\n",
    "pr_credits_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Transform the list of dictionaries in the cast column into sets with relevant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"name\"\n",
    "pr_credits_df = col_dict_to_set(pr_credits_df, \"cast\", key)\n",
    "pr_credits_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Filter crew dictionaries with Director as job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crew_col = \"crew\"\n",
    "job_field = \"job\"\n",
    "values = [\"Director\"]\n",
    "pr_credits_df = col_filter_dict_with_vals(pr_credits_df, crew_col, job_field, values)\n",
    "pr_credits_df = col_dict_to_set(pr_credits_df, crew_col, key)\n",
    "pr_credits_df = pr_credits_df[pr_credits_df[crew_col].notna()]\n",
    "pr_credits_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Get actors unique list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_key = \"order\"\n",
    "# Set the actor importances (the order key. The main actor is order 0) to consider for taking an actor as a node\n",
    "values = [0]\n",
    "get_value = lambda dict_: dict_.get(key)\n",
    "sel_order_actors_df = col_filter_dict_with_vals(\n",
    "    pr_credits_df, actors_col, order_key, values\n",
    ")\n",
    "actors_series = sel_order_actors_df[actors_col].explode()\n",
    "n_nan = actors_series.isna().sum()\n",
    "print(\"There are {:2d} missing values\".format(n_nan))\n",
    "actors_series = actors_series[actors_series.notna()]\n",
    "actors_list = list(set(actors_series.apply(get_value).to_list()))\n",
    "print(\"The list of actors contains {:2d} entries\".format(len(actors_list)))\n",
    "print(actors_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Get the actors that are in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_key = \"name\"\n",
    "values = actors_list\n",
    "pr_credits_df = col_filter_dict_with_vals(pr_credits_df, actors_col, name_key, values)\n",
    "pr_credits_df = pr_credits_df.explode(actors_col)\n",
    "pr_credits_df = pr_credits_df[pr_credits_df[actors_col].notna()]\n",
    "actors_series = pr_credits_df[actors_col]\n",
    "pr_credits_df = pr_credits_df.assign(\n",
    "    **{actors_col: pr_credits_df[actors_col].apply(get_value)}\n",
    ")\n",
    "pr_credits_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Remove actors taken as nodes from cast column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_cast_col = \"actor_cast\"\n",
    "pr_credits_df = pr_credits_df.reset_index(drop=True)\n",
    "remove_from_cast = lambda row: row[credits_df_json_cols[0]] - set({row[actors_col]})\n",
    "pr_credits_df = pr_credits_df.assign(\n",
    "    **{credits_df_json_cols[0]: pr_credits_df.apply(remove_from_cast, axis=1)}\n",
    ").drop(columns=\"title\")\n",
    "pr_credits_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. **Check if the actor was effectively removed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actor_name = \"Sam Worthington\"\n",
    "test_df = pr_credits_df[pr_credits_df[actors_col] == test_actor_name]\n",
    "for (idx, cast) in test_df[\"cast\"].items():\n",
    "    assert test_actor_name not in cast, \"Actor taken as node should not be in cast\"\n",
    "print(\"Test passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build actors index DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get actors index and most relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_cols = [\"name\", \"gender\", \"order\"]\n",
    "actors_idx_df = json_normalize(actors_series)[actor_cols]\n",
    "actors_idx_df = (\n",
    "    actors_idx_df.rename(columns={actor_cols[0]: actors_col})\n",
    "    .groupby(actors_col)\n",
    "    .aggregate({actor_cols[1]: max, actor_cols[2]: list})\n",
    "    .reset_index()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"actor_id\"})\n",
    ")\n",
    "actors_idx_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of unique actors is: \" + str(len(actors_idx_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build actors_index-credits DataFrame\n",
    "Add actor features to the credits DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_idx_credits_df = pr_credits_df.drop(new_movie_id_col, axis=1).merge(\n",
    "    actors_idx_df, right_on=actors_col, left_on=actors_col, how=\"inner\"\n",
    ")\n",
    "actors_idx_credits_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build movies index DataFrame\n",
    "Re-index movies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_id_col = \"movie_id\"\n",
    "# title_col = \"title\"\n",
    "# new_movie_id_col = \"new_movie_id\"\n",
    "# pr_movies_new_id_df = pr_movies_df.merge(new_movie_id_df, on=movie_id_col, how=\"inner\")\n",
    "# movies_idx_df = (\n",
    "#     pr_movies_new_id_df[[movie_id_col, title_col, new_movie_id_col]].drop_duplicates()\n",
    "#     #     .reset_index()\n",
    "#     .rename(columns={\"index\": new_movie_id_col})\n",
    "# )\n",
    "# movies_idx_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Number of unique movies: \" + str(len(movies_idx_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies_idx_csv_df = movies_idx_df.set_index(new_movie_id_col)\n",
    "# movies_idx_csv_df.to_csv(\"movies_idx.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build actors-movies-credits DataFrame\n",
    "Get actors from each movie and append their respective credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_col = \"movie_id\"\n",
    "actors_movies_credits_df = actors_idx_credits_df.merge(\n",
    "    pr_movies_df, right_on=movie_id_col, left_on=movie_id_col, how=\"inner\"\n",
    ")\n",
    "actors_movies_credits_df = (\n",
    "    actors_movies_credits_df.merge(\n",
    "        movies_idx_df.drop(columns=title_col),\n",
    "        right_on=movie_id_col,\n",
    "        left_on=movie_id_col,\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .drop(columns=movie_id_col)\n",
    "    .rename(columns={new_movie_id_col: movie_id_col})\n",
    ")\n",
    "actors_movies_credits_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build actors aggregated DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_union = lambda s: reduce(set.union, s)\n",
    "actor_id_col = \"actor_id\"\n",
    "actors_agg_df = (\n",
    "    actors_movies_credits_df.groupby(actors_col, as_index=False)\n",
    "    .aggregate(\n",
    "        {\n",
    "            \"movie_id\": set,\n",
    "            \"cast\": get_union,\n",
    "            \"crew\": get_union,\n",
    "            \"actor_id\": max,\n",
    "            \"gender\": max,\n",
    "            \"budget\": \"mean\",\n",
    "            \"genres\": get_union,\n",
    "            \"keywords\": get_union,\n",
    "            \"original_language\": set,\n",
    "            \"popularity\": \"mean\",\n",
    "            \"production_companies\": get_union,\n",
    "            \"production_countries\": get_union,\n",
    "            \"release_date\": list,\n",
    "            \"revenue\": \"mean\",\n",
    "            \"runtime\": sum,\n",
    "            \"status\": list,\n",
    "            \"title\": set,\n",
    "            \"vote_average\": \"mean\",\n",
    "            \"vote_count\": \"mean\",\n",
    "            norm_vote_avg_col: \"mean\",\n",
    "        }\n",
    "    )\n",
    "    .set_index(actor_id_col)\n",
    ")\n",
    "actors_agg_df.head()\n",
    "# Smoothness\n",
    "# supervised. Python-lovain labels will be our labels for the group.\n",
    "# We want to check if the features can explain the clusters\n",
    "# Use features as affinity to\n",
    "# logistic regresssion ads interpretability\n",
    "# predict average rating for a new actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_agg_df.to_pickle(\"actors_agg_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get the raw joined actor-movie dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_actor_df = pr_credits_df.set_index(\"movie_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_actor_movie_df = raw_actor_df.merge(valid_movies_df, on=movie_id_col, how=\"inner\")\n",
    "raw_actor_movie_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select 1 actor and compare two sets of movies he/she participated in. The first set is extracted from the raw actor-movie dataframe and the second from the aggregated actor dataframe. **Before testing any actor, make sure that none of the movies he/she participated in had been removed in the data cleaning process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actor_name = \"Sam Worthington\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_raw_actor_movie_df = raw_actor_movie_df[[actors_col, title_col]]\n",
    "from_raw_movies_performed_in = set(\n",
    "    from_raw_actor_movie_df[from_raw_actor_movie_df[actors_col] == test_actor_name][\n",
    "        title_col\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_agg_actor_movie_df = actors_agg_df[[actors_col, title_col]]\n",
    "from_agg_movies_performed_in = from_agg_actor_movie_df[\n",
    "    from_agg_actor_movie_df[actors_col] == test_actor_name\n",
    "][title_col].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    from_raw_movies_performed_in == from_agg_movies_performed_in\n",
    "), \"Aggregated actors dataframe has missing data or movies were removed in the data cleaning process\"\n",
    "print(\"Test passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Test whether the number of entries in the actors_agg_df is equal to the number of actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(actors_agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(actors_agg_df) == len(\n",
    "    set(list(raw_actor_movie_df[actors_col]))\n",
    "), \"Aggregated actors dataframe has missing data\"\n",
    "print(\"Test passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ntds_2019)",
   "language": "python",
   "name": "ntds_2019"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
